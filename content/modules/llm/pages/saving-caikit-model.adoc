[id='preparing-a-model-for-deployment']
= Preparing a model for deployment

After you converting the Google Flan model, you can deploy it by using the {productname-short} single-model server and the Caikit runtime.

To prepare it for deployment, you must move the model from your workbench to your S3-compatible object storage. You use the data connection that you created in the xref:setup:running-a-script-to-install-storage.adoc[Storage Data Connections] section and upload the model from a notebook. In the previous step, you converted the model to the Caikit format

=== Prerequisites

* You created the data connection `My Storage`.
+
image::create-workbench-form-data-connection.png[Workbench data connection form, 600]

* You added the `My Storage` data connection to your workbench.
+
image::ds-project-workbench-list-edit.png[Workbench edit form]


=== Procedure

. In your Jupyter environment, open the `2_save_model.ipynb` file.

. Follow the instructions in the notebook to make the model accessible in storage.

image::wb-notebook-save.png[Jupyter Notebook 2]

=== Verification

When you have completed the notebook instructions, tyou should see files listed in the directory/prefix: `models/flan-t5-small-caikit`

[.lines_space]
[.console-input]
[source,text]
----
models/flan-t5-small-caikit/artifacts/config.json
models/flan-t5-small-caikit/artifacts/generation_config.json
models/flan-t5-small-caikit/artifacts/model.safetensors
models/flan-t5-small-caikit/artifacts/special_tokens_map.json
models/flan-t5-small-caikit/artifacts/tokenizer.json
models/flan-t5-small-caikit/artifacts/tokenizer_config.json
models/flan-t5-small-caikit/config.yml
----

=== Next Step

xref:deploying-caikit-model.adoc[Deploying a model]
